{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from sklearn) (0.21.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.16.5)\n"
     ]
    }
   ],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/dc/9030097e5774fe02d1be3cb42eb54125d2c0607a6c11172f1dcad2b7fdcc/tensorflow-2.3.0-cp37-cp37m-win_amd64.whl\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.6)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.31.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.5)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from protobuf>=3.9.2->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.21.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (0.23)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\kandr\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (7.2.0)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow as tf\n",
    "#tensorflow.keras.__version__\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_time0bk_err1</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>2.479000e-04</td>\n",
       "      <td>-2.479000e-04</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>...</td>\n",
       "      <td>-81</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.105</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>1.490000e-05</td>\n",
       "      <td>-1.490000e-05</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>...</td>\n",
       "      <td>-176</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.176</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>-2.630000e-07</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>...</td>\n",
       "      <td>-174</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.201</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>3.760000e-06</td>\n",
       "      <td>-3.760000e-06</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.001130</td>\n",
       "      <td>...</td>\n",
       "      <td>-211</td>\n",
       "      <td>4.438</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.334</td>\n",
       "      <td>-0.133</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>1.050000e-05</td>\n",
       "      <td>-1.050000e-05</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>...</td>\n",
       "      <td>-232</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.315</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  koi_disposition  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0       CONFIRMED              0              0              0              0   \n",
       "1  FALSE POSITIVE              0              1              0              0   \n",
       "2  FALSE POSITIVE              0              1              0              0   \n",
       "3       CONFIRMED              0              0              0              0   \n",
       "4       CONFIRMED              0              0              0              0   \n",
       "\n",
       "   koi_period  koi_period_err1  koi_period_err2  koi_time0bk  \\\n",
       "0   54.418383     2.479000e-04    -2.479000e-04   162.513840   \n",
       "1   19.899140     1.490000e-05    -1.490000e-05   175.850252   \n",
       "2    1.736952     2.630000e-07    -2.630000e-07   170.307565   \n",
       "3    2.525592     3.760000e-06    -3.760000e-06   171.595550   \n",
       "4    4.134435     1.050000e-05    -1.050000e-05   172.979370   \n",
       "\n",
       "   koi_time0bk_err1  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0          0.003520  ...             -81      4.467           0.064   \n",
       "1          0.000581  ...            -176      4.544           0.044   \n",
       "2          0.000115  ...            -174      4.564           0.053   \n",
       "3          0.001130  ...            -211      4.438           0.070   \n",
       "4          0.001900  ...            -232      4.486           0.054   \n",
       "\n",
       "   koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2         ra  \\\n",
       "0          -0.096     0.927          0.105         -0.061  291.93423   \n",
       "1          -0.176     0.868          0.233         -0.078  297.00482   \n",
       "2          -0.168     0.791          0.201         -0.067  285.53461   \n",
       "3          -0.210     1.046          0.334         -0.133  288.75488   \n",
       "4          -0.229     0.972          0.315         -0.105  296.28613   \n",
       "\n",
       "         dec  koi_kepmag  \n",
       "0  48.141651      15.347  \n",
       "1  48.134129      15.436  \n",
       "2  48.285210      15.597  \n",
       "3  48.226200      15.509  \n",
       "4  48.224670      15.714  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# Drop the null columns where all values are null\n",
    "df = df.dropna(axis='columns', how='all')\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_disposition', 'koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co',\n",
       "       'koi_fpflag_ec', 'koi_period', 'koi_period_err1', 'koi_period_err2',\n",
       "       'koi_time0bk', 'koi_time0bk_err1', 'koi_time0bk_err2', 'koi_impact',\n",
       "       'koi_impact_err1', 'koi_impact_err2', 'koi_duration',\n",
       "       'koi_duration_err1', 'koi_duration_err2', 'koi_depth', 'koi_depth_err1',\n",
       "       'koi_depth_err2', 'koi_prad', 'koi_prad_err1', 'koi_prad_err2',\n",
       "       'koi_teq', 'koi_insol', 'koi_insol_err1', 'koi_insol_err2',\n",
       "       'koi_model_snr', 'koi_tce_plnt_num', 'koi_steff', 'koi_steff_err1',\n",
       "       'koi_steff_err2', 'koi_slogg', 'koi_slogg_err1', 'koi_slogg_err2',\n",
       "       'koi_srad', 'koi_srad_err1', 'koi_srad_err2', 'ra', 'dec',\n",
       "       'koi_kepmag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.586</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>...</td>\n",
       "      <td>2.83</td>\n",
       "      <td>443</td>\n",
       "      <td>9.11</td>\n",
       "      <td>25.8</td>\n",
       "      <td>5455</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.969</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>...</td>\n",
       "      <td>14.60</td>\n",
       "      <td>638</td>\n",
       "      <td>39.30</td>\n",
       "      <td>76.3</td>\n",
       "      <td>5853</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>1.276</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>...</td>\n",
       "      <td>33.46</td>\n",
       "      <td>1395</td>\n",
       "      <td>891.96</td>\n",
       "      <td>505.6</td>\n",
       "      <td>5805</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1406</td>\n",
       "      <td>926.16</td>\n",
       "      <td>40.9</td>\n",
       "      <td>6031</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.762</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>...</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1160</td>\n",
       "      <td>427.65</td>\n",
       "      <td>40.2</td>\n",
       "      <td>6046</td>\n",
       "      <td>4.486</td>\n",
       "      <td>0.972</td>\n",
       "      <td>296.28613</td>\n",
       "      <td>48.224670</td>\n",
       "      <td>15.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.589871</td>\n",
       "      <td>132.016100</td>\n",
       "      <td>4.296</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.765</td>\n",
       "      <td>4.80600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.11</td>\n",
       "      <td>929</td>\n",
       "      <td>176.40</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5638</td>\n",
       "      <td>4.296</td>\n",
       "      <td>1.088</td>\n",
       "      <td>298.74921</td>\n",
       "      <td>46.973351</td>\n",
       "      <td>14.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6987</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527699</td>\n",
       "      <td>131.705093</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.903</td>\n",
       "      <td>1.252</td>\n",
       "      <td>3.22210</td>\n",
       "      <td>...</td>\n",
       "      <td>29.35</td>\n",
       "      <td>2088</td>\n",
       "      <td>4500.53</td>\n",
       "      <td>453.3</td>\n",
       "      <td>5638</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.903</td>\n",
       "      <td>297.18875</td>\n",
       "      <td>47.093819</td>\n",
       "      <td>14.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.739849</td>\n",
       "      <td>133.001270</td>\n",
       "      <td>4.444</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3.11400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1608</td>\n",
       "      <td>1585.81</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6119</td>\n",
       "      <td>4.444</td>\n",
       "      <td>1.031</td>\n",
       "      <td>286.50937</td>\n",
       "      <td>47.163219</td>\n",
       "      <td>14.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>132.181750</td>\n",
       "      <td>4.447</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.86500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2218</td>\n",
       "      <td>5713.41</td>\n",
       "      <td>12.3</td>\n",
       "      <td>6173</td>\n",
       "      <td>4.447</td>\n",
       "      <td>1.041</td>\n",
       "      <td>294.16489</td>\n",
       "      <td>47.176281</td>\n",
       "      <td>15.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.856035</td>\n",
       "      <td>135.993300</td>\n",
       "      <td>4.385</td>\n",
       "      <td>1.193</td>\n",
       "      <td>0.134</td>\n",
       "      <td>3.07800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1266</td>\n",
       "      <td>607.42</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6469</td>\n",
       "      <td>4.385</td>\n",
       "      <td>1.193</td>\n",
       "      <td>297.00977</td>\n",
       "      <td>47.121021</td>\n",
       "      <td>14.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6991 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "0                 0              0              0              0   54.418383   \n",
       "1                 0              1              0              0   19.899140   \n",
       "2                 0              1              0              0    1.736952   \n",
       "3                 0              0              0              0    2.525592   \n",
       "4                 0              0              0              0    4.134435   \n",
       "...             ...            ...            ...            ...         ...   \n",
       "6986              0              0              0              1    8.589871   \n",
       "6987              0              1              1              0    0.527699   \n",
       "6988              0              0              0              0    1.739849   \n",
       "6989              0              0              1              0    0.681402   \n",
       "6990              0              0              1              1    4.856035   \n",
       "\n",
       "      koi_time0bk  koi_slogg  koi_srad  koi_impact  koi_duration  ...  \\\n",
       "0      162.513840      4.467     0.927       0.586       4.50700  ...   \n",
       "1      175.850252      4.544     0.868       0.969       1.78220  ...   \n",
       "2      170.307565      4.564     0.791       1.276       2.40641  ...   \n",
       "3      171.595550      4.438     1.046       0.701       1.65450  ...   \n",
       "4      172.979370      4.486     0.972       0.762       3.14020  ...   \n",
       "...           ...        ...       ...         ...           ...  ...   \n",
       "6986   132.016100      4.296     1.088       0.765       4.80600  ...   \n",
       "6987   131.705093      4.529     0.903       1.252       3.22210  ...   \n",
       "6988   133.001270      4.444     1.031       0.043       3.11400  ...   \n",
       "6989   132.181750      4.447     1.041       0.147       0.86500  ...   \n",
       "6990   135.993300      4.385     1.193       0.134       3.07800  ...   \n",
       "\n",
       "      koi_prad  koi_teq  koi_insol  koi_model_snr  koi_steff  koi_slogg  \\\n",
       "0         2.83      443       9.11           25.8       5455      4.467   \n",
       "1        14.60      638      39.30           76.3       5853      4.544   \n",
       "2        33.46     1395     891.96          505.6       5805      4.564   \n",
       "3         2.75     1406     926.16           40.9       6031      4.438   \n",
       "4         2.77     1160     427.65           40.2       6046      4.486   \n",
       "...        ...      ...        ...            ...        ...        ...   \n",
       "6986      1.11      929     176.40            8.4       5638      4.296   \n",
       "6987     29.35     2088    4500.53          453.3       5638      4.529   \n",
       "6988      0.72     1608    1585.81           10.6       6119      4.444   \n",
       "6989      1.07     2218    5713.41           12.3       6173      4.447   \n",
       "6990      1.05     1266     607.42            8.2       6469      4.385   \n",
       "\n",
       "      koi_srad         ra        dec  koi_kepmag  \n",
       "0        0.927  291.93423  48.141651      15.347  \n",
       "1        0.868  297.00482  48.134129      15.436  \n",
       "2        0.791  285.53461  48.285210      15.597  \n",
       "3        1.046  288.75488  48.226200      15.509  \n",
       "4        0.972  296.28613  48.224670      15.714  \n",
       "...        ...        ...        ...         ...  \n",
       "6986     1.088  298.74921  46.973351      14.478  \n",
       "6987     0.903  297.18875  47.093819      14.082  \n",
       "6988     1.031  286.50937  47.163219      14.757  \n",
       "6989     1.041  294.16489  47.176281      15.385  \n",
       "6990     1.193  297.00977  47.121021      14.826  \n",
       "\n",
       "[6991 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtemp = df[['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec', 'koi_period','koi_time0bk','koi_slogg','koi_srad','koi_impact','koi_duration','koi_depth','koi_prad','koi_teq','koi_insol','koi_model_snr','koi_steff','koi_slogg','koi_srad','ra','dec','koi_kepmag']]\n",
    "Xtemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['koi_disposition']]\n",
    "data_binary_encoded = pd.get_dummies(y, columns=[\"koi_disposition\"])\n",
    "data_binary_encoded.columns = [[\"candidate\",\"confirmed\",\"false_positive\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(Xtemp, data_binary_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12282572, 0.10010297, 0.12252498, 0.04895905, 0.04041636,\n",
       "       0.02690836, 0.01764624, 0.01731739, 0.04015034, 0.02904395,\n",
       "       0.05122564, 0.07453804, 0.03210544, 0.03198111, 0.12991152,\n",
       "       0.02114399, 0.01608106, 0.0173487 , 0.02089611, 0.01924253,\n",
       "       0.01963051])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.12991151877210172, 'koi_model_snr'),\n",
       " (0.12282572461964013, 'koi_fpflag_nt'),\n",
       " (0.12252497944188498, 'koi_fpflag_co'),\n",
       " (0.10010296526447064, 'koi_fpflag_ss'),\n",
       " (0.07453804375110083, 'koi_prad'),\n",
       " (0.05122563848247295, 'koi_depth'),\n",
       " (0.04895904569878345, 'koi_fpflag_ec'),\n",
       " (0.04041636206141344, 'koi_period'),\n",
       " (0.04015034036017476, 'koi_impact'),\n",
       " (0.032105439636079945, 'koi_teq'),\n",
       " (0.03198110914473922, 'koi_insol'),\n",
       " (0.029043945574134717, 'koi_duration'),\n",
       " (0.026908361167653116, 'koi_time0bk'),\n",
       " (0.02114399031576066, 'koi_steff'),\n",
       " (0.0208961066052518, 'ra'),\n",
       " (0.01963051283739296, 'koi_kepmag'),\n",
       " (0.019242526927912364, 'dec'),\n",
       " (0.017646241175743694, 'koi_slogg'),\n",
       " (0.017348698680615577, 'koi_srad'),\n",
       " (0.017317386890301014, 'koi_srad'),\n",
       " (0.01608106259237213, 'koi_slogg')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can sort the features by their importance\n",
    "sorted(zip(rf.feature_importances_, Xtemp), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_steff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.586</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>874.8</td>\n",
       "      <td>2.83</td>\n",
       "      <td>443</td>\n",
       "      <td>9.11</td>\n",
       "      <td>25.8</td>\n",
       "      <td>5455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.969</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10829.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>638</td>\n",
       "      <td>39.30</td>\n",
       "      <td>76.3</td>\n",
       "      <td>5853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>1.276</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8079.2</td>\n",
       "      <td>33.46</td>\n",
       "      <td>1395</td>\n",
       "      <td>891.96</td>\n",
       "      <td>505.6</td>\n",
       "      <td>5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.3</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1406</td>\n",
       "      <td>926.16</td>\n",
       "      <td>40.9</td>\n",
       "      <td>6031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.134435</td>\n",
       "      <td>172.979370</td>\n",
       "      <td>0.762</td>\n",
       "      <td>3.14020</td>\n",
       "      <td>686.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1160</td>\n",
       "      <td>427.65</td>\n",
       "      <td>40.2</td>\n",
       "      <td>6046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.589871</td>\n",
       "      <td>132.016100</td>\n",
       "      <td>0.765</td>\n",
       "      <td>4.80600</td>\n",
       "      <td>87.7</td>\n",
       "      <td>1.11</td>\n",
       "      <td>929</td>\n",
       "      <td>176.40</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6987</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527699</td>\n",
       "      <td>131.705093</td>\n",
       "      <td>1.252</td>\n",
       "      <td>3.22210</td>\n",
       "      <td>1579.2</td>\n",
       "      <td>29.35</td>\n",
       "      <td>2088</td>\n",
       "      <td>4500.53</td>\n",
       "      <td>453.3</td>\n",
       "      <td>5638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.739849</td>\n",
       "      <td>133.001270</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3.11400</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1608</td>\n",
       "      <td>1585.81</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>132.181750</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.86500</td>\n",
       "      <td>103.6</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2218</td>\n",
       "      <td>5713.41</td>\n",
       "      <td>12.3</td>\n",
       "      <td>6173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.856035</td>\n",
       "      <td>135.993300</td>\n",
       "      <td>0.134</td>\n",
       "      <td>3.07800</td>\n",
       "      <td>76.7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1266</td>\n",
       "      <td>607.42</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6991 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "0                 0              0              0              0   54.418383   \n",
       "1                 0              1              0              0   19.899140   \n",
       "2                 0              1              0              0    1.736952   \n",
       "3                 0              0              0              0    2.525592   \n",
       "4                 0              0              0              0    4.134435   \n",
       "...             ...            ...            ...            ...         ...   \n",
       "6986              0              0              0              1    8.589871   \n",
       "6987              0              1              1              0    0.527699   \n",
       "6988              0              0              0              0    1.739849   \n",
       "6989              0              0              1              0    0.681402   \n",
       "6990              0              0              1              1    4.856035   \n",
       "\n",
       "      koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  koi_teq  \\\n",
       "0      162.513840       0.586       4.50700      874.8      2.83      443   \n",
       "1      175.850252       0.969       1.78220    10829.0     14.60      638   \n",
       "2      170.307565       1.276       2.40641     8079.2     33.46     1395   \n",
       "3      171.595550       0.701       1.65450      603.3      2.75     1406   \n",
       "4      172.979370       0.762       3.14020      686.0      2.77     1160   \n",
       "...           ...         ...           ...        ...       ...      ...   \n",
       "6986   132.016100       0.765       4.80600       87.7      1.11      929   \n",
       "6987   131.705093       1.252       3.22210     1579.2     29.35     2088   \n",
       "6988   133.001270       0.043       3.11400       48.5      0.72     1608   \n",
       "6989   132.181750       0.147       0.86500      103.6      1.07     2218   \n",
       "6990   135.993300       0.134       3.07800       76.7      1.05     1266   \n",
       "\n",
       "      koi_insol  koi_model_snr  koi_steff  \n",
       "0          9.11           25.8       5455  \n",
       "1         39.30           76.3       5853  \n",
       "2        891.96          505.6       5805  \n",
       "3        926.16           40.9       6031  \n",
       "4        427.65           40.2       6046  \n",
       "...         ...            ...        ...  \n",
       "6986     176.40            8.4       5638  \n",
       "6987    4500.53          453.3       5638  \n",
       "6988    1585.81           10.6       6119  \n",
       "6989    5713.41           12.3       6173  \n",
       "6990     607.42            8.2       6469  \n",
       "\n",
       "[6991 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Xtemp.drop(columns=['ra','dec','koi_kepmag','koi_srad','koi_slogg'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['koi_fpflag_nt', 'koi_fpflag_ss', 'koi_fpflag_co', 'koi_fpflag_ec',\n",
       "       'koi_period', 'koi_time0bk', 'koi_impact', 'koi_duration', 'koi_depth',\n",
       "       'koi_prad', 'koi_teq', 'koi_insol', 'koi_model_snr', 'koi_steff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "selected_features = X.columns\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_steff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.548413</td>\n",
       "      <td>139.064020</td>\n",
       "      <td>1.0170</td>\n",
       "      <td>1.8720</td>\n",
       "      <td>102.9</td>\n",
       "      <td>3.89</td>\n",
       "      <td>899</td>\n",
       "      <td>154.84</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.754385</td>\n",
       "      <td>140.207320</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>3.3900</td>\n",
       "      <td>593.3</td>\n",
       "      <td>2.10</td>\n",
       "      <td>491</td>\n",
       "      <td>13.70</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.057336</td>\n",
       "      <td>131.792007</td>\n",
       "      <td>0.2620</td>\n",
       "      <td>1.5795</td>\n",
       "      <td>47337.0</td>\n",
       "      <td>14.59</td>\n",
       "      <td>1276</td>\n",
       "      <td>623.51</td>\n",
       "      <td>476.0</td>\n",
       "      <td>4664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>201.118319</td>\n",
       "      <td>187.569860</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>10.3280</td>\n",
       "      <td>584.8</td>\n",
       "      <td>2.28</td>\n",
       "      <td>300</td>\n",
       "      <td>1.92</td>\n",
       "      <td>34.7</td>\n",
       "      <td>5646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.649983</td>\n",
       "      <td>175.715600</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>10.2940</td>\n",
       "      <td>193.6</td>\n",
       "      <td>2.27</td>\n",
       "      <td>568</td>\n",
       "      <td>24.57</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  \\\n",
       "3563              0              0              0              0   10.548413   \n",
       "4099              0              0              0              0   24.754385   \n",
       "5460              0              0              0              0    1.057336   \n",
       "1091              0              0              0              0  201.118319   \n",
       "5999              0              0              0              0   91.649983   \n",
       "\n",
       "      koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  koi_teq  \\\n",
       "3563   139.064020      1.0170        1.8720      102.9      3.89      899   \n",
       "4099   140.207320      0.7090        3.3900      593.3      2.10      491   \n",
       "5460   131.792007      0.2620        1.5795    47337.0     14.59     1276   \n",
       "1091   187.569860      0.0010       10.3280      584.8      2.28      300   \n",
       "5999   175.715600      0.2136       10.2940      193.6      2.27      568   \n",
       "\n",
       "      koi_insol  koi_model_snr  koi_steff  \n",
       "3563     154.84           11.7       6047  \n",
       "4099      13.70           18.0       4852  \n",
       "5460     623.51          476.0       4664  \n",
       "1091       1.92           34.7       5646  \n",
       "5999      24.57            8.7       6705  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5243, 14) (5243, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled.shape, y_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using StandardScaler\n",
    "X2_scaler = StandardScaler().fit(X_train)\n",
    "X2_train_scaled = X2_scaler.transform(X_train)\n",
    "X2_test_scaled = X2_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# give no. of columns in y_train_categorical as input_dim\n",
    "model.add(Dense(units=100, activation='relu', input_dim=14))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "# give of columns in y_train_categorical as units\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1500      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 11,903\n",
      "Trainable params: 11,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(units=100, activation='relu', input_dim=14))\n",
    "model2.add(Dense(units=100, activation='relu'))\n",
    "model2.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               1500      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 11,903\n",
      "Trainable params: 11,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "164/164 - 0s - loss: 0.5434 - accuracy: 0.7028\n",
      "Epoch 2/60\n",
      "164/164 - 0s - loss: 0.3934 - accuracy: 0.7822\n",
      "Epoch 3/60\n",
      "164/164 - 0s - loss: 0.3828 - accuracy: 0.7864\n",
      "Epoch 4/60\n",
      "164/164 - 0s - loss: 0.3788 - accuracy: 0.7896\n",
      "Epoch 5/60\n",
      "164/164 - 0s - loss: 0.3746 - accuracy: 0.7934\n",
      "Epoch 6/60\n",
      "164/164 - 0s - loss: 0.3693 - accuracy: 0.8058\n",
      "Epoch 7/60\n",
      "164/164 - 0s - loss: 0.3685 - accuracy: 0.7984\n",
      "Epoch 8/60\n",
      "164/164 - 0s - loss: 0.3659 - accuracy: 0.8062\n",
      "Epoch 9/60\n",
      "164/164 - 0s - loss: 0.3612 - accuracy: 0.8097\n",
      "Epoch 10/60\n",
      "164/164 - 0s - loss: 0.3600 - accuracy: 0.8100\n",
      "Epoch 11/60\n",
      "164/164 - 0s - loss: 0.3575 - accuracy: 0.8110\n",
      "Epoch 12/60\n",
      "164/164 - 0s - loss: 0.3546 - accuracy: 0.8150\n",
      "Epoch 13/60\n",
      "164/164 - 0s - loss: 0.3533 - accuracy: 0.8161\n",
      "Epoch 14/60\n",
      "164/164 - 0s - loss: 0.3484 - accuracy: 0.8245\n",
      "Epoch 15/60\n",
      "164/164 - 0s - loss: 0.3492 - accuracy: 0.8150\n",
      "Epoch 16/60\n",
      "164/164 - 0s - loss: 0.3453 - accuracy: 0.8209\n",
      "Epoch 17/60\n",
      "164/164 - 0s - loss: 0.3397 - accuracy: 0.8262\n",
      "Epoch 18/60\n",
      "164/164 - 0s - loss: 0.3359 - accuracy: 0.8337\n",
      "Epoch 19/60\n",
      "164/164 - 0s - loss: 0.3360 - accuracy: 0.8278\n",
      "Epoch 20/60\n",
      "164/164 - 0s - loss: 0.3307 - accuracy: 0.8306\n",
      "Epoch 21/60\n",
      "164/164 - 0s - loss: 0.3276 - accuracy: 0.8409\n",
      "Epoch 22/60\n",
      "164/164 - 0s - loss: 0.3313 - accuracy: 0.8287\n",
      "Epoch 23/60\n",
      "164/164 - 0s - loss: 0.3250 - accuracy: 0.8379\n",
      "Epoch 24/60\n",
      "164/164 - 0s - loss: 0.3244 - accuracy: 0.8318\n",
      "Epoch 25/60\n",
      "164/164 - 0s - loss: 0.3186 - accuracy: 0.8440\n",
      "Epoch 26/60\n",
      "164/164 - 0s - loss: 0.3167 - accuracy: 0.8417\n",
      "Epoch 27/60\n",
      "164/164 - 0s - loss: 0.3129 - accuracy: 0.8491\n",
      "Epoch 28/60\n",
      "164/164 - 0s - loss: 0.3148 - accuracy: 0.8444\n",
      "Epoch 29/60\n",
      "164/164 - 0s - loss: 0.3138 - accuracy: 0.8415\n",
      "Epoch 30/60\n",
      "164/164 - 0s - loss: 0.3095 - accuracy: 0.8455\n",
      "Epoch 31/60\n",
      "164/164 - 0s - loss: 0.3089 - accuracy: 0.8459\n",
      "Epoch 32/60\n",
      "164/164 - 0s - loss: 0.3051 - accuracy: 0.8577\n",
      "Epoch 33/60\n",
      "164/164 - 0s - loss: 0.3028 - accuracy: 0.8554\n",
      "Epoch 34/60\n",
      "164/164 - 0s - loss: 0.3036 - accuracy: 0.8503\n",
      "Epoch 35/60\n",
      "164/164 - 0s - loss: 0.3007 - accuracy: 0.8560\n",
      "Epoch 36/60\n",
      "164/164 - 0s - loss: 0.3035 - accuracy: 0.8510\n",
      "Epoch 37/60\n",
      "164/164 - 0s - loss: 0.3014 - accuracy: 0.8522\n",
      "Epoch 38/60\n",
      "164/164 - 0s - loss: 0.2968 - accuracy: 0.8600\n",
      "Epoch 39/60\n",
      "164/164 - 0s - loss: 0.2930 - accuracy: 0.8579\n",
      "Epoch 40/60\n",
      "164/164 - 0s - loss: 0.2944 - accuracy: 0.8611\n",
      "Epoch 41/60\n",
      "164/164 - 0s - loss: 0.2912 - accuracy: 0.8611\n",
      "Epoch 42/60\n",
      "164/164 - 0s - loss: 0.2887 - accuracy: 0.8655\n",
      "Epoch 43/60\n",
      "164/164 - 0s - loss: 0.2922 - accuracy: 0.8617\n",
      "Epoch 44/60\n",
      "164/164 - 0s - loss: 0.2858 - accuracy: 0.8705\n",
      "Epoch 45/60\n",
      "164/164 - 0s - loss: 0.2855 - accuracy: 0.8680\n",
      "Epoch 46/60\n",
      "164/164 - 0s - loss: 0.2843 - accuracy: 0.8640\n",
      "Epoch 47/60\n",
      "164/164 - 0s - loss: 0.2813 - accuracy: 0.8724\n",
      "Epoch 48/60\n",
      "164/164 - 0s - loss: 0.2833 - accuracy: 0.8667\n",
      "Epoch 49/60\n",
      "164/164 - 0s - loss: 0.2820 - accuracy: 0.8692\n",
      "Epoch 50/60\n",
      "164/164 - 0s - loss: 0.2795 - accuracy: 0.8686\n",
      "Epoch 51/60\n",
      "164/164 - 0s - loss: 0.2759 - accuracy: 0.8779\n",
      "Epoch 52/60\n",
      "164/164 - 0s - loss: 0.2772 - accuracy: 0.8735\n",
      "Epoch 53/60\n",
      "164/164 - 0s - loss: 0.2783 - accuracy: 0.8726\n",
      "Epoch 54/60\n",
      "164/164 - 0s - loss: 0.2769 - accuracy: 0.8716\n",
      "Epoch 55/60\n",
      "164/164 - 0s - loss: 0.2747 - accuracy: 0.8766\n",
      "Epoch 56/60\n",
      "164/164 - 0s - loss: 0.2714 - accuracy: 0.8774\n",
      "Epoch 57/60\n",
      "164/164 - 0s - loss: 0.2710 - accuracy: 0.8770\n",
      "Epoch 58/60\n",
      "164/164 - 0s - loss: 0.2676 - accuracy: 0.8810\n",
      "Epoch 59/60\n",
      "164/164 - 0s - loss: 0.2703 - accuracy: 0.8724\n",
      "Epoch 60/60\n",
      "164/164 - 0s - loss: 0.2669 - accuracy: 0.8785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1eecb8f5048>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - loss: 0.2746 - accuracy: 0.8907\n",
      "Deep Neural Network - Loss: 0.2745939791202545, Accuracy: 0.8907322883605957\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "     X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "164/164 - 0s - loss: 0.2694 - accuracy: 0.8819\n",
      "Epoch 2/80\n",
      "164/164 - 0s - loss: 0.2705 - accuracy: 0.8747\n",
      "Epoch 3/80\n",
      "164/164 - 0s - loss: 0.2617 - accuracy: 0.8840\n",
      "Epoch 4/80\n",
      "164/164 - 0s - loss: 0.2687 - accuracy: 0.8777\n",
      "Epoch 5/80\n",
      "164/164 - 0s - loss: 0.2619 - accuracy: 0.8871\n",
      "Epoch 6/80\n",
      "164/164 - 0s - loss: 0.2615 - accuracy: 0.8835\n",
      "Epoch 7/80\n",
      "164/164 - 0s - loss: 0.2597 - accuracy: 0.8873\n",
      "Epoch 8/80\n",
      "164/164 - 0s - loss: 0.2598 - accuracy: 0.8854\n",
      "Epoch 9/80\n",
      "164/164 - 0s - loss: 0.2598 - accuracy: 0.8858\n",
      "Epoch 10/80\n",
      "164/164 - 0s - loss: 0.2553 - accuracy: 0.8919\n",
      "Epoch 11/80\n",
      "164/164 - 0s - loss: 0.2649 - accuracy: 0.8812\n",
      "Epoch 12/80\n",
      "164/164 - 0s - loss: 0.2613 - accuracy: 0.8858\n",
      "Epoch 13/80\n",
      "164/164 - 0s - loss: 0.2586 - accuracy: 0.8863\n",
      "Epoch 14/80\n",
      "164/164 - 0s - loss: 0.2562 - accuracy: 0.8907\n",
      "Epoch 15/80\n",
      "164/164 - 0s - loss: 0.2536 - accuracy: 0.8892\n",
      "Epoch 16/80\n",
      "164/164 - 0s - loss: 0.2573 - accuracy: 0.8852\n",
      "Epoch 17/80\n",
      "164/164 - 0s - loss: 0.2570 - accuracy: 0.8859\n",
      "Epoch 18/80\n",
      "164/164 - 0s - loss: 0.2526 - accuracy: 0.8886\n",
      "Epoch 19/80\n",
      "164/164 - 0s - loss: 0.2513 - accuracy: 0.8932\n",
      "Epoch 20/80\n",
      "164/164 - 0s - loss: 0.2612 - accuracy: 0.8808\n",
      "Epoch 21/80\n",
      "164/164 - 0s - loss: 0.2493 - accuracy: 0.8907\n",
      "Epoch 22/80\n",
      "164/164 - 0s - loss: 0.2561 - accuracy: 0.8901\n",
      "Epoch 23/80\n",
      "164/164 - 0s - loss: 0.2490 - accuracy: 0.8934\n",
      "Epoch 24/80\n",
      "164/164 - 0s - loss: 0.2487 - accuracy: 0.8917\n",
      "Epoch 25/80\n",
      "164/164 - 0s - loss: 0.2502 - accuracy: 0.8936\n",
      "Epoch 26/80\n",
      "164/164 - 0s - loss: 0.2493 - accuracy: 0.8922\n",
      "Epoch 27/80\n",
      "164/164 - 0s - loss: 0.2478 - accuracy: 0.8903\n",
      "Epoch 28/80\n",
      "164/164 - 0s - loss: 0.2453 - accuracy: 0.8917\n",
      "Epoch 29/80\n",
      "164/164 - 0s - loss: 0.2431 - accuracy: 0.8966\n",
      "Epoch 30/80\n",
      "164/164 - 0s - loss: 0.2473 - accuracy: 0.8909\n",
      "Epoch 31/80\n",
      "164/164 - 0s - loss: 0.2481 - accuracy: 0.8890\n",
      "Epoch 32/80\n",
      "164/164 - 0s - loss: 0.2449 - accuracy: 0.8911\n",
      "Epoch 33/80\n",
      "164/164 - 0s - loss: 0.2473 - accuracy: 0.8932\n",
      "Epoch 34/80\n",
      "164/164 - 0s - loss: 0.2445 - accuracy: 0.8949\n",
      "Epoch 35/80\n",
      "164/164 - 0s - loss: 0.2457 - accuracy: 0.8926\n",
      "Epoch 36/80\n",
      "164/164 - 0s - loss: 0.2474 - accuracy: 0.8928\n",
      "Epoch 37/80\n",
      "164/164 - 0s - loss: 0.2415 - accuracy: 0.8964\n",
      "Epoch 38/80\n",
      "164/164 - 0s - loss: 0.2463 - accuracy: 0.8924\n",
      "Epoch 39/80\n",
      "164/164 - 0s - loss: 0.2419 - accuracy: 0.8985\n",
      "Epoch 40/80\n",
      "164/164 - 0s - loss: 0.2461 - accuracy: 0.8920\n",
      "Epoch 41/80\n",
      "164/164 - 0s - loss: 0.2415 - accuracy: 0.8955\n",
      "Epoch 42/80\n",
      "164/164 - 0s - loss: 0.2406 - accuracy: 0.8989\n",
      "Epoch 43/80\n",
      "164/164 - 0s - loss: 0.2403 - accuracy: 0.8980\n",
      "Epoch 44/80\n",
      "164/164 - 0s - loss: 0.2391 - accuracy: 0.8970\n",
      "Epoch 45/80\n",
      "164/164 - 0s - loss: 0.2444 - accuracy: 0.8907\n",
      "Epoch 46/80\n",
      "164/164 - 0s - loss: 0.2453 - accuracy: 0.8936\n",
      "Epoch 47/80\n",
      "164/164 - 0s - loss: 0.2452 - accuracy: 0.8934\n",
      "Epoch 48/80\n",
      "164/164 - 0s - loss: 0.2460 - accuracy: 0.8907\n",
      "Epoch 49/80\n",
      "164/164 - 0s - loss: 0.2422 - accuracy: 0.8949\n",
      "Epoch 50/80\n",
      "164/164 - 0s - loss: 0.2389 - accuracy: 0.8968\n",
      "Epoch 51/80\n",
      "164/164 - 0s - loss: 0.2393 - accuracy: 0.8961\n",
      "Epoch 52/80\n",
      "164/164 - 0s - loss: 0.2402 - accuracy: 0.8941\n",
      "Epoch 53/80\n",
      "164/164 - 0s - loss: 0.2373 - accuracy: 0.8980\n",
      "Epoch 54/80\n",
      "164/164 - 0s - loss: 0.2380 - accuracy: 0.8966\n",
      "Epoch 55/80\n",
      "164/164 - 0s - loss: 0.2398 - accuracy: 0.8974\n",
      "Epoch 56/80\n",
      "164/164 - 0s - loss: 0.2394 - accuracy: 0.8970\n",
      "Epoch 57/80\n",
      "164/164 - 0s - loss: 0.2400 - accuracy: 0.8964\n",
      "Epoch 58/80\n",
      "164/164 - 0s - loss: 0.2403 - accuracy: 0.8997\n",
      "Epoch 59/80\n",
      "164/164 - 0s - loss: 0.2390 - accuracy: 0.8961\n",
      "Epoch 60/80\n",
      "164/164 - 0s - loss: 0.2352 - accuracy: 0.8999\n",
      "Epoch 61/80\n",
      "164/164 - 0s - loss: 0.2367 - accuracy: 0.8993\n",
      "Epoch 62/80\n",
      "164/164 - 0s - loss: 0.2403 - accuracy: 0.8953\n",
      "Epoch 63/80\n",
      "164/164 - 0s - loss: 0.2377 - accuracy: 0.8955\n",
      "Epoch 64/80\n",
      "164/164 - 0s - loss: 0.2388 - accuracy: 0.8970\n",
      "Epoch 65/80\n",
      "164/164 - 0s - loss: 0.2429 - accuracy: 0.8938\n",
      "Epoch 66/80\n",
      "164/164 - 0s - loss: 0.2417 - accuracy: 0.8915\n",
      "Epoch 67/80\n",
      "164/164 - 0s - loss: 0.2371 - accuracy: 0.8962\n",
      "Epoch 68/80\n",
      "164/164 - 0s - loss: 0.2360 - accuracy: 0.8987\n",
      "Epoch 69/80\n",
      "164/164 - 0s - loss: 0.2353 - accuracy: 0.8991\n",
      "Epoch 70/80\n",
      "164/164 - 0s - loss: 0.2355 - accuracy: 0.8962\n",
      "Epoch 71/80\n",
      "164/164 - 0s - loss: 0.2400 - accuracy: 0.8959\n",
      "Epoch 72/80\n",
      "164/164 - 0s - loss: 0.2362 - accuracy: 0.8972\n",
      "Epoch 73/80\n",
      "164/164 - 0s - loss: 0.2335 - accuracy: 0.8997\n",
      "Epoch 74/80\n",
      "164/164 - 0s - loss: 0.2362 - accuracy: 0.8980\n",
      "Epoch 75/80\n",
      "164/164 - 0s - loss: 0.2346 - accuracy: 0.8968\n",
      "Epoch 76/80\n",
      "164/164 - 0s - loss: 0.2334 - accuracy: 0.8987\n",
      "Epoch 77/80\n",
      "164/164 - 0s - loss: 0.2366 - accuracy: 0.8949\n",
      "Epoch 78/80\n",
      "164/164 - 0s - loss: 0.2401 - accuracy: 0.8928\n",
      "Epoch 79/80\n",
      "164/164 - 0s - loss: 0.2359 - accuracy: 0.8978\n",
      "Epoch 80/80\n",
      "164/164 - 0s - loss: 0.2356 - accuracy: 0.8972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1eecb9c0088>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "     X_train_scaled,\n",
    "     y_train_categorical,\n",
    "     epochs=80,\n",
    "     shuffle=True,\n",
    "     verbose=2\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - loss: 0.2748 - accuracy: 0.8896\n",
      "Deep Neural Network - Loss: 0.27476245164871216, Accuracy: 0.8895881175994873\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "     X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "164/164 - 0s - loss: 0.2396 - accuracy: 0.8953\n",
      "Epoch 2/100\n",
      "164/164 - 0s - loss: 0.2324 - accuracy: 0.8961\n",
      "Epoch 3/100\n",
      "164/164 - 0s - loss: 0.2351 - accuracy: 0.8978\n",
      "Epoch 4/100\n",
      "164/164 - 0s - loss: 0.2324 - accuracy: 0.8964\n",
      "Epoch 5/100\n",
      "164/164 - 0s - loss: 0.2309 - accuracy: 0.8980\n",
      "Epoch 6/100\n",
      "164/164 - 0s - loss: 0.2328 - accuracy: 0.8964\n",
      "Epoch 7/100\n",
      "164/164 - 0s - loss: 0.2351 - accuracy: 0.8966\n",
      "Epoch 8/100\n",
      "164/164 - 0s - loss: 0.2328 - accuracy: 0.9001\n",
      "Epoch 9/100\n",
      "164/164 - 0s - loss: 0.2344 - accuracy: 0.8991\n",
      "Epoch 10/100\n",
      "164/164 - 0s - loss: 0.2308 - accuracy: 0.9012\n",
      "Epoch 11/100\n",
      "164/164 - 0s - loss: 0.2331 - accuracy: 0.8997\n",
      "Epoch 12/100\n",
      "164/164 - 0s - loss: 0.2353 - accuracy: 0.8966\n",
      "Epoch 13/100\n",
      "164/164 - 0s - loss: 0.2296 - accuracy: 0.8981\n",
      "Epoch 14/100\n",
      "164/164 - 0s - loss: 0.2324 - accuracy: 0.8966\n",
      "Epoch 15/100\n",
      "164/164 - 0s - loss: 0.2283 - accuracy: 0.8985\n",
      "Epoch 16/100\n",
      "164/164 - 0s - loss: 0.2312 - accuracy: 0.8972\n",
      "Epoch 17/100\n",
      "164/164 - 0s - loss: 0.2292 - accuracy: 0.9020\n",
      "Epoch 18/100\n",
      "164/164 - 0s - loss: 0.2319 - accuracy: 0.8966\n",
      "Epoch 19/100\n",
      "164/164 - 0s - loss: 0.2299 - accuracy: 0.9006\n",
      "Epoch 20/100\n",
      "164/164 - 0s - loss: 0.2310 - accuracy: 0.8985\n",
      "Epoch 21/100\n",
      "164/164 - 0s - loss: 0.2309 - accuracy: 0.8985\n",
      "Epoch 22/100\n",
      "164/164 - 0s - loss: 0.2342 - accuracy: 0.8930\n",
      "Epoch 23/100\n",
      "164/164 - 0s - loss: 0.2287 - accuracy: 0.9022\n",
      "Epoch 24/100\n",
      "164/164 - 0s - loss: 0.2297 - accuracy: 0.9010\n",
      "Epoch 25/100\n",
      "164/164 - 0s - loss: 0.2288 - accuracy: 0.9023\n",
      "Epoch 26/100\n",
      "164/164 - 0s - loss: 0.2311 - accuracy: 0.9006\n",
      "Epoch 27/100\n",
      "164/164 - 0s - loss: 0.2256 - accuracy: 0.9008\n",
      "Epoch 28/100\n",
      "164/164 - 0s - loss: 0.2256 - accuracy: 0.8999\n",
      "Epoch 29/100\n",
      "164/164 - 0s - loss: 0.2274 - accuracy: 0.8980\n",
      "Epoch 30/100\n",
      "164/164 - 0s - loss: 0.2280 - accuracy: 0.8985\n",
      "Epoch 31/100\n",
      "164/164 - 0s - loss: 0.2263 - accuracy: 0.9018\n",
      "Epoch 32/100\n",
      "164/164 - 0s - loss: 0.2340 - accuracy: 0.8978\n",
      "Epoch 33/100\n",
      "164/164 - 0s - loss: 0.2297 - accuracy: 0.8993\n",
      "Epoch 34/100\n",
      "164/164 - 0s - loss: 0.2278 - accuracy: 0.9020\n",
      "Epoch 35/100\n",
      "164/164 - 0s - loss: 0.2268 - accuracy: 0.9023\n",
      "Epoch 36/100\n",
      "164/164 - 0s - loss: 0.2277 - accuracy: 0.8993\n",
      "Epoch 37/100\n",
      "164/164 - 0s - loss: 0.2315 - accuracy: 0.8993\n",
      "Epoch 38/100\n",
      "164/164 - 0s - loss: 0.2248 - accuracy: 0.9052\n",
      "Epoch 39/100\n",
      "164/164 - 0s - loss: 0.2256 - accuracy: 0.8991\n",
      "Epoch 40/100\n",
      "164/164 - 0s - loss: 0.2266 - accuracy: 0.9031\n",
      "Epoch 41/100\n",
      "164/164 - 0s - loss: 0.2260 - accuracy: 0.8995\n",
      "Epoch 42/100\n",
      "164/164 - 0s - loss: 0.2287 - accuracy: 0.8997\n",
      "Epoch 43/100\n",
      "164/164 - 0s - loss: 0.2252 - accuracy: 0.9008\n",
      "Epoch 44/100\n",
      "164/164 - 0s - loss: 0.2242 - accuracy: 0.9010\n",
      "Epoch 45/100\n",
      "164/164 - 0s - loss: 0.2253 - accuracy: 0.9054\n",
      "Epoch 46/100\n",
      "164/164 - 0s - loss: 0.2247 - accuracy: 0.9016\n",
      "Epoch 47/100\n",
      "164/164 - 0s - loss: 0.2237 - accuracy: 0.9004\n",
      "Epoch 48/100\n",
      "164/164 - 0s - loss: 0.2292 - accuracy: 0.8972\n",
      "Epoch 49/100\n",
      "164/164 - 0s - loss: 0.2249 - accuracy: 0.9004\n",
      "Epoch 50/100\n",
      "164/164 - 0s - loss: 0.2261 - accuracy: 0.9029\n",
      "Epoch 51/100\n",
      "164/164 - 0s - loss: 0.2235 - accuracy: 0.8974\n",
      "Epoch 52/100\n",
      "164/164 - 0s - loss: 0.2257 - accuracy: 0.8989\n",
      "Epoch 53/100\n",
      "164/164 - 0s - loss: 0.2240 - accuracy: 0.9022\n",
      "Epoch 54/100\n",
      "164/164 - 0s - loss: 0.2220 - accuracy: 0.9010\n",
      "Epoch 55/100\n",
      "164/164 - 0s - loss: 0.2253 - accuracy: 0.9012\n",
      "Epoch 56/100\n",
      "164/164 - 0s - loss: 0.2229 - accuracy: 0.9016\n",
      "Epoch 57/100\n",
      "164/164 - 0s - loss: 0.2239 - accuracy: 0.9033\n",
      "Epoch 58/100\n",
      "164/164 - 0s - loss: 0.2217 - accuracy: 0.9027\n",
      "Epoch 59/100\n",
      "164/164 - 0s - loss: 0.2232 - accuracy: 0.8999\n",
      "Epoch 60/100\n",
      "164/164 - 0s - loss: 0.2199 - accuracy: 0.9025\n",
      "Epoch 61/100\n",
      "164/164 - 0s - loss: 0.2261 - accuracy: 0.9027\n",
      "Epoch 62/100\n",
      "164/164 - 0s - loss: 0.2206 - accuracy: 0.9048\n",
      "Epoch 63/100\n",
      "164/164 - 0s - loss: 0.2219 - accuracy: 0.9052\n",
      "Epoch 64/100\n",
      "164/164 - 0s - loss: 0.2231 - accuracy: 0.9041\n",
      "Epoch 65/100\n",
      "164/164 - 0s - loss: 0.2219 - accuracy: 0.9006\n",
      "Epoch 66/100\n",
      "164/164 - 0s - loss: 0.2211 - accuracy: 0.9037\n",
      "Epoch 67/100\n",
      "164/164 - 0s - loss: 0.2191 - accuracy: 0.9050\n",
      "Epoch 68/100\n",
      "164/164 - 0s - loss: 0.2242 - accuracy: 0.9001\n",
      "Epoch 69/100\n",
      "164/164 - 0s - loss: 0.2250 - accuracy: 0.8976\n",
      "Epoch 70/100\n",
      "164/164 - 0s - loss: 0.2220 - accuracy: 0.9018\n",
      "Epoch 71/100\n",
      "164/164 - 0s - loss: 0.2204 - accuracy: 0.9033\n",
      "Epoch 72/100\n",
      "164/164 - 0s - loss: 0.2193 - accuracy: 0.9052\n",
      "Epoch 73/100\n",
      "164/164 - 0s - loss: 0.2197 - accuracy: 0.9033\n",
      "Epoch 74/100\n",
      "164/164 - 0s - loss: 0.2193 - accuracy: 0.9060\n",
      "Epoch 75/100\n",
      "164/164 - 0s - loss: 0.2215 - accuracy: 0.9035\n",
      "Epoch 76/100\n",
      "164/164 - 0s - loss: 0.2188 - accuracy: 0.9054\n",
      "Epoch 77/100\n",
      "164/164 - 0s - loss: 0.2207 - accuracy: 0.9043\n",
      "Epoch 78/100\n",
      "164/164 - 0s - loss: 0.2224 - accuracy: 0.9031\n",
      "Epoch 79/100\n",
      "164/164 - 0s - loss: 0.2231 - accuracy: 0.9010\n",
      "Epoch 80/100\n",
      "164/164 - 0s - loss: 0.2210 - accuracy: 0.9033\n",
      "Epoch 81/100\n",
      "164/164 - 0s - loss: 0.2178 - accuracy: 0.9058\n",
      "Epoch 82/100\n",
      "164/164 - 0s - loss: 0.2212 - accuracy: 0.9043\n",
      "Epoch 83/100\n",
      "164/164 - 0s - loss: 0.2232 - accuracy: 0.8991\n",
      "Epoch 84/100\n",
      "164/164 - 0s - loss: 0.2202 - accuracy: 0.9062\n",
      "Epoch 85/100\n",
      "164/164 - 0s - loss: 0.2172 - accuracy: 0.9052\n",
      "Epoch 86/100\n",
      "164/164 - 0s - loss: 0.2180 - accuracy: 0.9041\n",
      "Epoch 87/100\n",
      "164/164 - 0s - loss: 0.2235 - accuracy: 0.9008\n",
      "Epoch 88/100\n",
      "164/164 - 0s - loss: 0.2147 - accuracy: 0.9033\n",
      "Epoch 89/100\n",
      "164/164 - 0s - loss: 0.2213 - accuracy: 0.9037\n",
      "Epoch 90/100\n",
      "164/164 - 0s - loss: 0.2154 - accuracy: 0.9065\n",
      "Epoch 91/100\n",
      "164/164 - 0s - loss: 0.2191 - accuracy: 0.9023\n",
      "Epoch 92/100\n",
      "164/164 - 0s - loss: 0.2172 - accuracy: 0.9084\n",
      "Epoch 93/100\n",
      "164/164 - 0s - loss: 0.2209 - accuracy: 0.9004\n",
      "Epoch 94/100\n",
      "164/164 - 0s - loss: 0.2174 - accuracy: 0.9060\n",
      "Epoch 95/100\n",
      "164/164 - 0s - loss: 0.2197 - accuracy: 0.9033\n",
      "Epoch 96/100\n",
      "164/164 - 0s - loss: 0.2182 - accuracy: 0.9050\n",
      "Epoch 97/100\n",
      "164/164 - 0s - loss: 0.2186 - accuracy: 0.9056\n",
      "Epoch 98/100\n",
      "164/164 - 0s - loss: 0.2157 - accuracy: 0.9056\n",
      "Epoch 99/100\n",
      "164/164 - 0s - loss: 0.2153 - accuracy: 0.9054\n",
      "Epoch 100/100\n",
      "164/164 - 0s - loss: 0.2177 - accuracy: 0.9054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1eecbae6208>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "     X_train_scaled,\n",
    "     y_train_categorical,\n",
    "     epochs=100,\n",
    "     shuffle=True,\n",
    "     verbose=2\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - loss: 0.2655 - accuracy: 0.9010\n",
      "Deep Neural Network - Loss: 0.2655249536037445, Accuracy: 0.9010297656059265\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "164/164 - 0s - loss: 0.2181 - accuracy: 0.9079\n",
      "Epoch 2/150\n",
      "164/164 - 0s - loss: 0.2198 - accuracy: 0.9043\n",
      "Epoch 3/150\n",
      "164/164 - 0s - loss: 0.2160 - accuracy: 0.9046\n",
      "Epoch 4/150\n",
      "164/164 - 0s - loss: 0.2150 - accuracy: 0.9064\n",
      "Epoch 5/150\n",
      "164/164 - 0s - loss: 0.2142 - accuracy: 0.9035\n",
      "Epoch 6/150\n",
      "164/164 - 0s - loss: 0.2137 - accuracy: 0.9041\n",
      "Epoch 7/150\n",
      "164/164 - 0s - loss: 0.2178 - accuracy: 0.9037\n",
      "Epoch 8/150\n",
      "164/164 - 0s - loss: 0.2224 - accuracy: 0.9056\n",
      "Epoch 9/150\n",
      "164/164 - 0s - loss: 0.2166 - accuracy: 0.9043\n",
      "Epoch 10/150\n",
      "164/164 - 0s - loss: 0.2135 - accuracy: 0.9046\n",
      "Epoch 11/150\n",
      "164/164 - 0s - loss: 0.2163 - accuracy: 0.9041\n",
      "Epoch 12/150\n",
      "164/164 - 0s - loss: 0.2121 - accuracy: 0.9060\n",
      "Epoch 13/150\n",
      "164/164 - 0s - loss: 0.2117 - accuracy: 0.9075\n",
      "Epoch 14/150\n",
      "164/164 - 0s - loss: 0.2149 - accuracy: 0.9044\n",
      "Epoch 15/150\n",
      "164/164 - 0s - loss: 0.2115 - accuracy: 0.9092\n",
      "Epoch 16/150\n",
      "164/164 - 0s - loss: 0.2119 - accuracy: 0.9060\n",
      "Epoch 17/150\n",
      "164/164 - 0s - loss: 0.2159 - accuracy: 0.9069\n",
      "Epoch 18/150\n",
      "164/164 - 0s - loss: 0.2123 - accuracy: 0.9064\n",
      "Epoch 19/150\n",
      "164/164 - 0s - loss: 0.2173 - accuracy: 0.9067\n",
      "Epoch 20/150\n",
      "164/164 - 0s - loss: 0.2162 - accuracy: 0.9048\n",
      "Epoch 21/150\n",
      "164/164 - 0s - loss: 0.2210 - accuracy: 0.9035\n",
      "Epoch 22/150\n",
      "164/164 - 0s - loss: 0.2114 - accuracy: 0.9081\n",
      "Epoch 23/150\n",
      "164/164 - 0s - loss: 0.2109 - accuracy: 0.9064\n",
      "Epoch 24/150\n",
      "164/164 - 0s - loss: 0.2174 - accuracy: 0.9060\n",
      "Epoch 25/150\n",
      "164/164 - 0s - loss: 0.2101 - accuracy: 0.9054\n",
      "Epoch 26/150\n",
      "164/164 - 0s - loss: 0.2108 - accuracy: 0.9073\n",
      "Epoch 27/150\n",
      "164/164 - 0s - loss: 0.2141 - accuracy: 0.9039\n",
      "Epoch 28/150\n",
      "164/164 - 0s - loss: 0.2118 - accuracy: 0.9069\n",
      "Epoch 29/150\n",
      "164/164 - 0s - loss: 0.2096 - accuracy: 0.9086\n",
      "Epoch 30/150\n",
      "164/164 - 0s - loss: 0.2107 - accuracy: 0.9079\n",
      "Epoch 31/150\n",
      "164/164 - 0s - loss: 0.2152 - accuracy: 0.9088\n",
      "Epoch 32/150\n",
      "164/164 - 0s - loss: 0.2135 - accuracy: 0.9035\n",
      "Epoch 33/150\n",
      "164/164 - 0s - loss: 0.2084 - accuracy: 0.9105\n",
      "Epoch 34/150\n",
      "164/164 - 0s - loss: 0.2097 - accuracy: 0.9083\n",
      "Epoch 35/150\n",
      "164/164 - 0s - loss: 0.2075 - accuracy: 0.9083\n",
      "Epoch 36/150\n",
      "164/164 - 0s - loss: 0.2114 - accuracy: 0.9052\n",
      "Epoch 37/150\n",
      "164/164 - 0s - loss: 0.2108 - accuracy: 0.9081\n",
      "Epoch 38/150\n",
      "164/164 - 0s - loss: 0.2109 - accuracy: 0.9088\n",
      "Epoch 39/150\n",
      "164/164 - 0s - loss: 0.2061 - accuracy: 0.9111\n",
      "Epoch 40/150\n",
      "164/164 - 0s - loss: 0.2123 - accuracy: 0.9062\n",
      "Epoch 41/150\n",
      "164/164 - 0s - loss: 0.2104 - accuracy: 0.9100\n",
      "Epoch 42/150\n",
      "164/164 - 0s - loss: 0.2104 - accuracy: 0.9098\n",
      "Epoch 43/150\n",
      "164/164 - 0s - loss: 0.2107 - accuracy: 0.9077\n",
      "Epoch 44/150\n",
      "164/164 - 0s - loss: 0.2108 - accuracy: 0.9094\n",
      "Epoch 45/150\n",
      "164/164 - 0s - loss: 0.2099 - accuracy: 0.9083\n",
      "Epoch 46/150\n",
      "164/164 - 0s - loss: 0.2124 - accuracy: 0.9073\n",
      "Epoch 47/150\n",
      "164/164 - 0s - loss: 0.2125 - accuracy: 0.9035\n",
      "Epoch 48/150\n",
      "164/164 - 0s - loss: 0.2082 - accuracy: 0.9077\n",
      "Epoch 49/150\n",
      "164/164 - 0s - loss: 0.2093 - accuracy: 0.9084\n",
      "Epoch 50/150\n",
      "164/164 - 0s - loss: 0.2080 - accuracy: 0.9083\n",
      "Epoch 51/150\n",
      "164/164 - 0s - loss: 0.2068 - accuracy: 0.9115\n",
      "Epoch 52/150\n",
      "164/164 - 0s - loss: 0.2112 - accuracy: 0.9081\n",
      "Epoch 53/150\n",
      "164/164 - 0s - loss: 0.2090 - accuracy: 0.9092\n",
      "Epoch 54/150\n",
      "164/164 - 0s - loss: 0.2083 - accuracy: 0.9075\n",
      "Epoch 55/150\n",
      "164/164 - 0s - loss: 0.2094 - accuracy: 0.9083\n",
      "Epoch 56/150\n",
      "164/164 - 0s - loss: 0.2122 - accuracy: 0.9109\n",
      "Epoch 57/150\n",
      "164/164 - 0s - loss: 0.2070 - accuracy: 0.9126\n",
      "Epoch 58/150\n",
      "164/164 - 0s - loss: 0.2090 - accuracy: 0.9056\n",
      "Epoch 59/150\n",
      "164/164 - 0s - loss: 0.2080 - accuracy: 0.9100\n",
      "Epoch 60/150\n",
      "164/164 - 0s - loss: 0.2087 - accuracy: 0.9084\n",
      "Epoch 61/150\n",
      "164/164 - 0s - loss: 0.2100 - accuracy: 0.9102\n",
      "Epoch 62/150\n",
      "164/164 - 0s - loss: 0.2088 - accuracy: 0.9081\n",
      "Epoch 63/150\n",
      "164/164 - 0s - loss: 0.2069 - accuracy: 0.9104\n",
      "Epoch 64/150\n",
      "164/164 - 0s - loss: 0.2143 - accuracy: 0.9084\n",
      "Epoch 65/150\n",
      "164/164 - 0s - loss: 0.2051 - accuracy: 0.9107\n",
      "Epoch 66/150\n",
      "164/164 - 0s - loss: 0.2073 - accuracy: 0.9086\n",
      "Epoch 67/150\n",
      "164/164 - 0s - loss: 0.2044 - accuracy: 0.9111\n",
      "Epoch 68/150\n",
      "164/164 - 0s - loss: 0.2072 - accuracy: 0.9107\n",
      "Epoch 69/150\n",
      "164/164 - 0s - loss: 0.2014 - accuracy: 0.9130\n",
      "Epoch 70/150\n",
      "164/164 - 0s - loss: 0.2050 - accuracy: 0.9107\n",
      "Epoch 71/150\n",
      "164/164 - 0s - loss: 0.2045 - accuracy: 0.9081\n",
      "Epoch 72/150\n",
      "164/164 - 0s - loss: 0.2081 - accuracy: 0.9107\n",
      "Epoch 73/150\n",
      "164/164 - 0s - loss: 0.2048 - accuracy: 0.9088\n",
      "Epoch 74/150\n",
      "164/164 - 0s - loss: 0.2058 - accuracy: 0.9104\n",
      "Epoch 75/150\n",
      "164/164 - 0s - loss: 0.2056 - accuracy: 0.9100\n",
      "Epoch 76/150\n",
      "164/164 - 0s - loss: 0.2072 - accuracy: 0.9104\n",
      "Epoch 77/150\n",
      "164/164 - 0s - loss: 0.2077 - accuracy: 0.9100\n",
      "Epoch 78/150\n",
      "164/164 - 0s - loss: 0.2095 - accuracy: 0.9088\n",
      "Epoch 79/150\n",
      "164/164 - 0s - loss: 0.2030 - accuracy: 0.9081\n",
      "Epoch 80/150\n",
      "164/164 - 0s - loss: 0.2029 - accuracy: 0.9107\n",
      "Epoch 81/150\n",
      "164/164 - 0s - loss: 0.2030 - accuracy: 0.9117\n",
      "Epoch 82/150\n",
      "164/164 - 0s - loss: 0.2064 - accuracy: 0.9115\n",
      "Epoch 83/150\n",
      "164/164 - 0s - loss: 0.2056 - accuracy: 0.9073\n",
      "Epoch 84/150\n",
      "164/164 - 0s - loss: 0.2058 - accuracy: 0.9094\n",
      "Epoch 85/150\n",
      "164/164 - 0s - loss: 0.2028 - accuracy: 0.9146\n",
      "Epoch 86/150\n",
      "164/164 - 0s - loss: 0.2084 - accuracy: 0.9083\n",
      "Epoch 87/150\n",
      "164/164 - 0s - loss: 0.2022 - accuracy: 0.9105\n",
      "Epoch 88/150\n",
      "164/164 - 0s - loss: 0.2084 - accuracy: 0.9105\n",
      "Epoch 89/150\n",
      "164/164 - 0s - loss: 0.2018 - accuracy: 0.9111\n",
      "Epoch 90/150\n",
      "164/164 - 0s - loss: 0.2011 - accuracy: 0.9123\n",
      "Epoch 91/150\n",
      "164/164 - 0s - loss: 0.2027 - accuracy: 0.9128\n",
      "Epoch 92/150\n",
      "164/164 - 0s - loss: 0.2021 - accuracy: 0.9119\n",
      "Epoch 93/150\n",
      "164/164 - 0s - loss: 0.2028 - accuracy: 0.9098\n",
      "Epoch 94/150\n",
      "164/164 - 0s - loss: 0.2019 - accuracy: 0.9113\n",
      "Epoch 95/150\n",
      "164/164 - 0s - loss: 0.1999 - accuracy: 0.9096\n",
      "Epoch 96/150\n",
      "164/164 - 0s - loss: 0.2012 - accuracy: 0.9125\n",
      "Epoch 97/150\n",
      "164/164 - 0s - loss: 0.2003 - accuracy: 0.9109\n",
      "Epoch 98/150\n",
      "164/164 - 0s - loss: 0.2005 - accuracy: 0.9104\n",
      "Epoch 99/150\n",
      "164/164 - 0s - loss: 0.2035 - accuracy: 0.9105\n",
      "Epoch 100/150\n",
      "164/164 - 0s - loss: 0.1996 - accuracy: 0.9132\n",
      "Epoch 101/150\n",
      "164/164 - 0s - loss: 0.2044 - accuracy: 0.9125\n",
      "Epoch 102/150\n",
      "164/164 - 0s - loss: 0.1984 - accuracy: 0.9146\n",
      "Epoch 103/150\n",
      "164/164 - 0s - loss: 0.2020 - accuracy: 0.9125\n",
      "Epoch 104/150\n",
      "164/164 - 0s - loss: 0.2055 - accuracy: 0.9075\n",
      "Epoch 105/150\n",
      "164/164 - 0s - loss: 0.2010 - accuracy: 0.9104\n",
      "Epoch 106/150\n",
      "164/164 - 0s - loss: 0.2009 - accuracy: 0.9168\n",
      "Epoch 107/150\n",
      "164/164 - 0s - loss: 0.2035 - accuracy: 0.9094\n",
      "Epoch 108/150\n",
      "164/164 - 0s - loss: 0.1980 - accuracy: 0.9132\n",
      "Epoch 109/150\n",
      "164/164 - 0s - loss: 0.2007 - accuracy: 0.9138\n",
      "Epoch 110/150\n",
      "164/164 - 0s - loss: 0.2018 - accuracy: 0.9115\n",
      "Epoch 111/150\n",
      "164/164 - 0s - loss: 0.1979 - accuracy: 0.9149\n",
      "Epoch 112/150\n",
      "164/164 - 0s - loss: 0.1995 - accuracy: 0.9149\n",
      "Epoch 113/150\n",
      "164/164 - 0s - loss: 0.1991 - accuracy: 0.9119\n",
      "Epoch 114/150\n",
      "164/164 - 0s - loss: 0.1992 - accuracy: 0.9128\n",
      "Epoch 115/150\n",
      "164/164 - 0s - loss: 0.2005 - accuracy: 0.9117\n",
      "Epoch 116/150\n",
      "164/164 - 0s - loss: 0.1980 - accuracy: 0.9109\n",
      "Epoch 117/150\n",
      "164/164 - 0s - loss: 0.1998 - accuracy: 0.9115\n",
      "Epoch 118/150\n",
      "164/164 - 0s - loss: 0.2024 - accuracy: 0.9119\n",
      "Epoch 119/150\n",
      "164/164 - 0s - loss: 0.2000 - accuracy: 0.9126\n",
      "Epoch 120/150\n",
      "164/164 - 0s - loss: 0.2017 - accuracy: 0.9140\n",
      "Epoch 121/150\n",
      "164/164 - 0s - loss: 0.1967 - accuracy: 0.9138\n",
      "Epoch 122/150\n",
      "164/164 - 0s - loss: 0.1979 - accuracy: 0.9149\n",
      "Epoch 123/150\n",
      "164/164 - 0s - loss: 0.1960 - accuracy: 0.9157\n",
      "Epoch 124/150\n",
      "164/164 - 0s - loss: 0.1998 - accuracy: 0.9132\n",
      "Epoch 125/150\n",
      "164/164 - 0s - loss: 0.1969 - accuracy: 0.9130\n",
      "Epoch 126/150\n",
      "164/164 - 0s - loss: 0.2000 - accuracy: 0.9132\n",
      "Epoch 127/150\n",
      "164/164 - 0s - loss: 0.2021 - accuracy: 0.9090\n",
      "Epoch 128/150\n",
      "164/164 - 0s - loss: 0.1980 - accuracy: 0.9151\n",
      "Epoch 129/150\n",
      "164/164 - 0s - loss: 0.1979 - accuracy: 0.9157\n",
      "Epoch 130/150\n",
      "164/164 - 0s - loss: 0.2003 - accuracy: 0.9086\n",
      "Epoch 131/150\n",
      "164/164 - 0s - loss: 0.1993 - accuracy: 0.9111\n",
      "Epoch 132/150\n",
      "164/164 - 0s - loss: 0.1940 - accuracy: 0.9172\n",
      "Epoch 133/150\n",
      "164/164 - 0s - loss: 0.2010 - accuracy: 0.9123\n",
      "Epoch 134/150\n",
      "164/164 - 0s - loss: 0.1984 - accuracy: 0.9147\n",
      "Epoch 135/150\n",
      "164/164 - 0s - loss: 0.1942 - accuracy: 0.9159\n",
      "Epoch 136/150\n",
      "164/164 - 0s - loss: 0.1998 - accuracy: 0.9146\n",
      "Epoch 137/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 0s - loss: 0.1954 - accuracy: 0.9144\n",
      "Epoch 138/150\n",
      "164/164 - 0s - loss: 0.2008 - accuracy: 0.9130\n",
      "Epoch 139/150\n",
      "164/164 - 0s - loss: 0.2002 - accuracy: 0.9128\n",
      "Epoch 140/150\n",
      "164/164 - 0s - loss: 0.1941 - accuracy: 0.9153\n",
      "Epoch 141/150\n",
      "164/164 - 0s - loss: 0.1971 - accuracy: 0.9117\n",
      "Epoch 142/150\n",
      "164/164 - 0s - loss: 0.1970 - accuracy: 0.9163\n",
      "Epoch 143/150\n",
      "164/164 - 0s - loss: 0.1974 - accuracy: 0.9132\n",
      "Epoch 144/150\n",
      "164/164 - 0s - loss: 0.1946 - accuracy: 0.9163\n",
      "Epoch 145/150\n",
      "164/164 - 0s - loss: 0.1984 - accuracy: 0.9134\n",
      "Epoch 146/150\n",
      "164/164 - 0s - loss: 0.1956 - accuracy: 0.9163\n",
      "Epoch 147/150\n",
      "164/164 - 0s - loss: 0.1973 - accuracy: 0.9138\n",
      "Epoch 148/150\n",
      "164/164 - 0s - loss: 0.1941 - accuracy: 0.9176\n",
      "Epoch 149/150\n",
      "164/164 - 0s - loss: 0.2015 - accuracy: 0.9092\n",
      "Epoch 150/150\n",
      "164/164 - 0s - loss: 0.1957 - accuracy: 0.9142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1eecbbac948>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This one scores better than epochs 60,80,and 100\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=150,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "164/164 - 0s - loss: 0.4984 - accuracy: 0.7625\n",
      "Epoch 2/150\n",
      "164/164 - 0s - loss: 0.3691 - accuracy: 0.8114\n",
      "Epoch 3/150\n",
      "164/164 - 0s - loss: 0.3535 - accuracy: 0.8161\n",
      "Epoch 4/150\n",
      "164/164 - 0s - loss: 0.3446 - accuracy: 0.8198\n",
      "Epoch 5/150\n",
      "164/164 - 0s - loss: 0.3388 - accuracy: 0.8251\n",
      "Epoch 6/150\n",
      "164/164 - 0s - loss: 0.3350 - accuracy: 0.8240\n",
      "Epoch 7/150\n",
      "164/164 - 0s - loss: 0.3290 - accuracy: 0.8255\n",
      "Epoch 8/150\n",
      "164/164 - 0s - loss: 0.3300 - accuracy: 0.8211\n",
      "Epoch 9/150\n",
      "164/164 - 0s - loss: 0.3226 - accuracy: 0.8306\n",
      "Epoch 10/150\n",
      "164/164 - 0s - loss: 0.3200 - accuracy: 0.8318\n",
      "Epoch 11/150\n",
      "164/164 - 0s - loss: 0.3207 - accuracy: 0.8356\n",
      "Epoch 12/150\n",
      "164/164 - 0s - loss: 0.3188 - accuracy: 0.8341\n",
      "Epoch 13/150\n",
      "164/164 - 0s - loss: 0.3135 - accuracy: 0.8367\n",
      "Epoch 14/150\n",
      "164/164 - 0s - loss: 0.3110 - accuracy: 0.8356\n",
      "Epoch 15/150\n",
      "164/164 - 0s - loss: 0.3103 - accuracy: 0.8386\n",
      "Epoch 16/150\n",
      "164/164 - 0s - loss: 0.3073 - accuracy: 0.8402\n",
      "Epoch 17/150\n",
      "164/164 - 0s - loss: 0.3076 - accuracy: 0.8386\n",
      "Epoch 18/150\n",
      "164/164 - 0s - loss: 0.3060 - accuracy: 0.8381\n",
      "Epoch 19/150\n",
      "164/164 - 0s - loss: 0.3038 - accuracy: 0.8411\n",
      "Epoch 20/150\n",
      "164/164 - 0s - loss: 0.3001 - accuracy: 0.8480\n",
      "Epoch 21/150\n",
      "164/164 - 0s - loss: 0.2995 - accuracy: 0.8476\n",
      "Epoch 22/150\n",
      "164/164 - 0s - loss: 0.2961 - accuracy: 0.8501\n",
      "Epoch 23/150\n",
      "164/164 - 0s - loss: 0.2982 - accuracy: 0.8423\n",
      "Epoch 24/150\n",
      "164/164 - 0s - loss: 0.3005 - accuracy: 0.8400\n",
      "Epoch 25/150\n",
      "164/164 - 0s - loss: 0.2933 - accuracy: 0.8524\n",
      "Epoch 26/150\n",
      "164/164 - 0s - loss: 0.2932 - accuracy: 0.8505\n",
      "Epoch 27/150\n",
      "164/164 - 0s - loss: 0.2893 - accuracy: 0.8493\n",
      "Epoch 28/150\n",
      "164/164 - 0s - loss: 0.2916 - accuracy: 0.8491\n",
      "Epoch 29/150\n",
      "164/164 - 0s - loss: 0.2866 - accuracy: 0.8592\n",
      "Epoch 30/150\n",
      "164/164 - 0s - loss: 0.2851 - accuracy: 0.8499\n",
      "Epoch 31/150\n",
      "164/164 - 0s - loss: 0.2837 - accuracy: 0.8632\n",
      "Epoch 32/150\n",
      "164/164 - 0s - loss: 0.2854 - accuracy: 0.8560\n",
      "Epoch 33/150\n",
      "164/164 - 0s - loss: 0.2823 - accuracy: 0.8589\n",
      "Epoch 34/150\n",
      "164/164 - 0s - loss: 0.2784 - accuracy: 0.8587\n",
      "Epoch 35/150\n",
      "164/164 - 0s - loss: 0.2788 - accuracy: 0.8539\n",
      "Epoch 36/150\n",
      "164/164 - 0s - loss: 0.2800 - accuracy: 0.8579\n",
      "Epoch 37/150\n",
      "164/164 - 0s - loss: 0.2761 - accuracy: 0.8638\n",
      "Epoch 38/150\n",
      "164/164 - 0s - loss: 0.2733 - accuracy: 0.8606\n",
      "Epoch 39/150\n",
      "164/164 - 0s - loss: 0.2748 - accuracy: 0.8640\n",
      "Epoch 40/150\n",
      "164/164 - 0s - loss: 0.2699 - accuracy: 0.8652\n",
      "Epoch 41/150\n",
      "164/164 - 0s - loss: 0.2678 - accuracy: 0.8682\n",
      "Epoch 42/150\n",
      "164/164 - 0s - loss: 0.2696 - accuracy: 0.8686\n",
      "Epoch 43/150\n",
      "164/164 - 0s - loss: 0.2896 - accuracy: 0.8709\n",
      "Epoch 44/150\n",
      "164/164 - 0s - loss: 0.2621 - accuracy: 0.8709\n",
      "Epoch 45/150\n",
      "164/164 - 0s - loss: 0.2607 - accuracy: 0.8730\n",
      "Epoch 46/150\n",
      "164/164 - 0s - loss: 0.2634 - accuracy: 0.8730\n",
      "Epoch 47/150\n",
      "164/164 - 0s - loss: 0.2585 - accuracy: 0.8751\n",
      "Epoch 48/150\n",
      "164/164 - 0s - loss: 0.2562 - accuracy: 0.8762\n",
      "Epoch 49/150\n",
      "164/164 - 0s - loss: 0.2599 - accuracy: 0.8680\n",
      "Epoch 50/150\n",
      "164/164 - 0s - loss: 0.2569 - accuracy: 0.8753\n",
      "Epoch 51/150\n",
      "164/164 - 0s - loss: 0.2551 - accuracy: 0.8774\n",
      "Epoch 52/150\n",
      "164/164 - 0s - loss: 0.2584 - accuracy: 0.8707\n",
      "Epoch 53/150\n",
      "164/164 - 0s - loss: 0.2508 - accuracy: 0.8800\n",
      "Epoch 54/150\n",
      "164/164 - 0s - loss: 0.2487 - accuracy: 0.8835\n",
      "Epoch 55/150\n",
      "164/164 - 0s - loss: 0.2517 - accuracy: 0.8793\n",
      "Epoch 56/150\n",
      "164/164 - 0s - loss: 0.2470 - accuracy: 0.8827\n",
      "Epoch 57/150\n",
      "164/164 - 0s - loss: 0.2485 - accuracy: 0.8793\n",
      "Epoch 58/150\n",
      "164/164 - 0s - loss: 0.2453 - accuracy: 0.8850\n",
      "Epoch 59/150\n",
      "164/164 - 0s - loss: 0.2415 - accuracy: 0.8858\n",
      "Epoch 60/150\n",
      "164/164 - 0s - loss: 0.2405 - accuracy: 0.8890\n",
      "Epoch 61/150\n",
      "164/164 - 0s - loss: 0.2454 - accuracy: 0.8816\n",
      "Epoch 62/150\n",
      "164/164 - 0s - loss: 0.2400 - accuracy: 0.8882\n",
      "Epoch 63/150\n",
      "164/164 - 0s - loss: 0.2436 - accuracy: 0.8831\n",
      "Epoch 64/150\n",
      "164/164 - 0s - loss: 0.2369 - accuracy: 0.8873\n",
      "Epoch 65/150\n",
      "164/164 - 0s - loss: 0.2373 - accuracy: 0.8899\n",
      "Epoch 66/150\n",
      "164/164 - 0s - loss: 0.2324 - accuracy: 0.8920\n",
      "Epoch 67/150\n",
      "164/164 - 0s - loss: 0.2551 - accuracy: 0.8875\n",
      "Epoch 68/150\n",
      "164/164 - 0s - loss: 0.2333 - accuracy: 0.8957\n",
      "Epoch 69/150\n",
      "164/164 - 0s - loss: 0.2292 - accuracy: 0.8961\n",
      "Epoch 70/150\n",
      "164/164 - 0s - loss: 0.2331 - accuracy: 0.8903\n",
      "Epoch 71/150\n",
      "164/164 - 0s - loss: 0.2373 - accuracy: 0.8873\n",
      "Epoch 72/150\n",
      "164/164 - 0s - loss: 0.2409 - accuracy: 0.8816\n",
      "Epoch 73/150\n",
      "164/164 - 0s - loss: 0.2260 - accuracy: 0.8941\n",
      "Epoch 74/150\n",
      "164/164 - 0s - loss: 0.2258 - accuracy: 0.8989\n",
      "Epoch 75/150\n",
      "164/164 - 0s - loss: 0.2310 - accuracy: 0.8913\n",
      "Epoch 76/150\n",
      "164/164 - 0s - loss: 0.2274 - accuracy: 0.8961\n",
      "Epoch 77/150\n",
      "164/164 - 0s - loss: 0.2265 - accuracy: 0.8964\n",
      "Epoch 78/150\n",
      "164/164 - 0s - loss: 0.2262 - accuracy: 0.8953\n",
      "Epoch 79/150\n",
      "164/164 - 0s - loss: 0.2202 - accuracy: 0.9010\n",
      "Epoch 80/150\n",
      "164/164 - 0s - loss: 0.2220 - accuracy: 0.8926\n",
      "Epoch 81/150\n",
      "164/164 - 0s - loss: 0.2188 - accuracy: 0.9006\n",
      "Epoch 82/150\n",
      "164/164 - 0s - loss: 0.2223 - accuracy: 0.8974\n",
      "Epoch 83/150\n",
      "164/164 - 0s - loss: 0.2207 - accuracy: 0.9004\n",
      "Epoch 84/150\n",
      "164/164 - 0s - loss: 0.2176 - accuracy: 0.9008\n",
      "Epoch 85/150\n",
      "164/164 - 0s - loss: 0.2165 - accuracy: 0.9020\n",
      "Epoch 86/150\n",
      "164/164 - 0s - loss: 0.2164 - accuracy: 0.9012\n",
      "Epoch 87/150\n",
      "164/164 - 0s - loss: 0.2192 - accuracy: 0.8968\n",
      "Epoch 88/150\n",
      "164/164 - 0s - loss: 0.2232 - accuracy: 0.8936\n",
      "Epoch 89/150\n",
      "164/164 - 0s - loss: 0.2161 - accuracy: 0.9006\n",
      "Epoch 90/150\n",
      "164/164 - 0s - loss: 0.2174 - accuracy: 0.9050\n",
      "Epoch 91/150\n",
      "164/164 - 0s - loss: 0.2091 - accuracy: 0.9083\n",
      "Epoch 92/150\n",
      "164/164 - 0s - loss: 0.2104 - accuracy: 0.9041\n",
      "Epoch 93/150\n",
      "164/164 - 0s - loss: 0.2133 - accuracy: 0.9039\n",
      "Epoch 94/150\n",
      "164/164 - 0s - loss: 0.2255 - accuracy: 0.8959\n",
      "Epoch 95/150\n",
      "164/164 - 0s - loss: 0.2099 - accuracy: 0.9071\n",
      "Epoch 96/150\n",
      "164/164 - 0s - loss: 0.2090 - accuracy: 0.9086\n",
      "Epoch 97/150\n",
      "164/164 - 0s - loss: 0.2074 - accuracy: 0.9043\n",
      "Epoch 98/150\n",
      "164/164 - 0s - loss: 0.2095 - accuracy: 0.9023\n",
      "Epoch 99/150\n",
      "164/164 - 0s - loss: 0.2089 - accuracy: 0.9037\n",
      "Epoch 100/150\n",
      "164/164 - 0s - loss: 0.2020 - accuracy: 0.9098\n",
      "Epoch 101/150\n",
      "164/164 - 0s - loss: 0.2169 - accuracy: 0.9023\n",
      "Epoch 102/150\n",
      "164/164 - 0s - loss: 0.2043 - accuracy: 0.9100\n",
      "Epoch 103/150\n",
      "164/164 - 0s - loss: 0.2081 - accuracy: 0.9029\n",
      "Epoch 104/150\n",
      "164/164 - 0s - loss: 0.2022 - accuracy: 0.9113\n",
      "Epoch 105/150\n",
      "164/164 - 0s - loss: 0.2051 - accuracy: 0.9081\n",
      "Epoch 106/150\n",
      "164/164 - 0s - loss: 0.2070 - accuracy: 0.9039\n",
      "Epoch 107/150\n",
      "164/164 - 0s - loss: 0.1996 - accuracy: 0.9123\n",
      "Epoch 108/150\n",
      "164/164 - 0s - loss: 0.2098 - accuracy: 0.9004\n",
      "Epoch 109/150\n",
      "164/164 - 0s - loss: 0.2029 - accuracy: 0.9079\n",
      "Epoch 110/150\n",
      "164/164 - 0s - loss: 0.1976 - accuracy: 0.9107\n",
      "Epoch 111/150\n",
      "164/164 - 0s - loss: 0.1992 - accuracy: 0.9098\n",
      "Epoch 112/150\n",
      "164/164 - 0s - loss: 0.2028 - accuracy: 0.9088\n",
      "Epoch 113/150\n",
      "164/164 - 0s - loss: 0.1975 - accuracy: 0.9115\n",
      "Epoch 114/150\n",
      "164/164 - 0s - loss: 0.1990 - accuracy: 0.9098\n",
      "Epoch 115/150\n",
      "164/164 - 0s - loss: 0.2037 - accuracy: 0.9073\n",
      "Epoch 116/150\n",
      "164/164 - 0s - loss: 0.2027 - accuracy: 0.9090\n",
      "Epoch 117/150\n",
      "164/164 - 0s - loss: 0.1947 - accuracy: 0.9105\n",
      "Epoch 118/150\n",
      "164/164 - 0s - loss: 0.1985 - accuracy: 0.9123\n",
      "Epoch 119/150\n",
      "164/164 - 0s - loss: 0.2024 - accuracy: 0.9090\n",
      "Epoch 120/150\n",
      "164/164 - 0s - loss: 0.1978 - accuracy: 0.9121\n",
      "Epoch 121/150\n",
      "164/164 - 0s - loss: 0.2028 - accuracy: 0.9113\n",
      "Epoch 122/150\n",
      "164/164 - 0s - loss: 0.1917 - accuracy: 0.9107\n",
      "Epoch 123/150\n",
      "164/164 - 0s - loss: 0.1915 - accuracy: 0.9165\n",
      "Epoch 124/150\n",
      "164/164 - 0s - loss: 0.1949 - accuracy: 0.9119\n",
      "Epoch 125/150\n",
      "164/164 - 0s - loss: 0.1933 - accuracy: 0.9119\n",
      "Epoch 126/150\n",
      "164/164 - 0s - loss: 0.1941 - accuracy: 0.9117\n",
      "Epoch 127/150\n",
      "164/164 - 0s - loss: 0.1907 - accuracy: 0.9144\n",
      "Epoch 128/150\n",
      "164/164 - 0s - loss: 0.1891 - accuracy: 0.9155\n",
      "Epoch 129/150\n",
      "164/164 - 0s - loss: 0.1897 - accuracy: 0.9172\n",
      "Epoch 130/150\n",
      "164/164 - 0s - loss: 0.1882 - accuracy: 0.9180\n",
      "Epoch 131/150\n",
      "164/164 - 0s - loss: 0.1900 - accuracy: 0.9123\n",
      "Epoch 132/150\n",
      "164/164 - 0s - loss: 0.1928 - accuracy: 0.9138\n",
      "Epoch 133/150\n",
      "164/164 - 0s - loss: 0.1875 - accuracy: 0.9147\n",
      "Epoch 134/150\n",
      "164/164 - 0s - loss: 0.2113 - accuracy: 0.9146\n",
      "Epoch 135/150\n",
      "164/164 - 0s - loss: 0.1872 - accuracy: 0.9205\n",
      "Epoch 136/150\n",
      "164/164 - 0s - loss: 0.1926 - accuracy: 0.9193\n",
      "Epoch 137/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 - 0s - loss: 0.1808 - accuracy: 0.9226\n",
      "Epoch 138/150\n",
      "164/164 - 0s - loss: 0.1881 - accuracy: 0.9130\n",
      "Epoch 139/150\n",
      "164/164 - 0s - loss: 0.1886 - accuracy: 0.9165\n",
      "Epoch 140/150\n",
      "164/164 - 0s - loss: 0.1827 - accuracy: 0.9180\n",
      "Epoch 141/150\n",
      "164/164 - 0s - loss: 0.1856 - accuracy: 0.9182\n",
      "Epoch 142/150\n",
      "164/164 - 0s - loss: 0.1849 - accuracy: 0.9201\n",
      "Epoch 143/150\n",
      "164/164 - 0s - loss: 0.1874 - accuracy: 0.9176\n",
      "Epoch 144/150\n",
      "164/164 - 0s - loss: 0.1851 - accuracy: 0.9149\n",
      "Epoch 145/150\n",
      "164/164 - 0s - loss: 0.1838 - accuracy: 0.9186\n",
      "Epoch 146/150\n",
      "164/164 - 0s - loss: 0.1807 - accuracy: 0.9197\n",
      "Epoch 147/150\n",
      "164/164 - 0s - loss: 0.1810 - accuracy: 0.9193\n",
      "Epoch 148/150\n",
      "164/164 - 0s - loss: 0.1803 - accuracy: 0.9195\n",
      "Epoch 149/150\n",
      "164/164 - 0s - loss: 0.1773 - accuracy: 0.9226\n",
      "Epoch 150/150\n",
      "164/164 - 0s - loss: 0.1763 - accuracy: 0.9229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1eecbbd8288>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing with StandardScaler\n",
    "model2.fit(\n",
    "    X2_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=150,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - loss: 0.3282 - accuracy: 0.8856\n",
      "Deep Neural Network - Loss: 0.3281726539134979, Accuracy: 0.8855835199356079\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler Accuracy\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 - 0s - loss: 0.4709 - accuracy: 0.8833\n",
      "Deep Neural Network - Loss: 0.4708515703678131, Accuracy: 0.8832951784133911\n"
     ]
    }
   ],
   "source": [
    "# StandardScaler\n",
    "model_loss, model_accuracy = model2.evaluate(\n",
    "    X2_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-38-d437f8374ee3>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Predicted classes: ['CONFIRMED' 'FALSE POSITIVE' 'FALSE POSITIVE' 'CONFIRMED'\n",
      " 'FALSE POSITIVE']\n",
      "Actual Labels: [['CONFIRMED'], ['FALSE POSITIVE'], ['FALSE POSITIVE'], ['CONFIRMED'], ['FALSE POSITIVE']]\n"
     ]
    }
   ],
   "source": [
    "# make predictions and print the results\n",
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {y_test.values[:5].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning with MinMaxScaler scored higher accuracy percentage (88.56%) then StandardScaler (88.32%). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
